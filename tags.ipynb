{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import psycopg2\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your database credentials\n",
    "db_config = {\n",
    "    'dbname': 'data',\n",
    "    'user': 'adrien',\n",
    "    'password': 'adrien9583!',\n",
    "    'host': 'localhost',\n",
    "    'port': '5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definition_of_tags(text):\n",
    "    words = text.split()\n",
    "    tags_and_words = {\n",
    "        \"règlement écrit\": [\"stationnement\", \"surface\", \"plancher\", \"zone\", \"occupations\", \"utilisations\", \"sol\", \"article\"],\n",
    "        \"zonage\": [\"zone\", \"stationnement\", \"occupations\", \"utilisations\"],\n",
    "        \"padd\": [\"developpement\", \"services\", \"secteurs\", \"protéger\", \"maitriser\", \"trame\", \"préserver\", \"améliorer\", \"ville-center\", \"reconquete\", \"zones\", \"équipements\", \"urbain\", \"padd\",\"espaces\",\"maitriser\"],\n",
    "        \"Arrêté municipal/préfectoral/départemental/régional\": [\"vu\",\"code\",\"L.\",\"R.\",\"arrété\",\"présent\",\"article\",\"définition\",\"loi\"]\n",
    "    }\n",
    "\n",
    "    stop_words = []\n",
    "    with open(\"stop_words.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                stop_words.append(word)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    top_words = word_counts.most_common(5)\n",
    "\n",
    "    # Initialize a list and a set to store tagged words\n",
    "    tagged_words = []\n",
    "    unique_tagged_words = set()\n",
    "\n",
    "    # Initialize dictionaries to store word counts and tag counts\n",
    "    word_counts = {}\n",
    "    tag_counts = {}\n",
    "    tagged_words_by_tag = {}\n",
    "\n",
    "    # Iterate through words and apply tags based on word lists\n",
    "    for word in words:\n",
    "        for tag, word_list in tags_and_words.items():\n",
    "            if word.lower() in word_list:\n",
    "                tagged_word = (word, tag)\n",
    "                if tag not in tagged_words_by_tag:\n",
    "                    tagged_words_by_tag[tag] = []\n",
    "                tagged_words_by_tag[tag].append(tagged_word)\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "                tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "    # Calculate the total percentage for each tag and store in a dictionary\n",
    "    tag_percentages = {}\n",
    "    total_percentage = 0\n",
    "    for tag, tagged_words in tagged_words_by_tag.items():\n",
    "        total_count_for_tag = tag_counts[tag]\n",
    "        tag_percentage = sum(\n",
    "            word_counts[word] / total_count_for_tag * 100 for word, _ in tagged_words)\n",
    "        tag_percentages[tag] = tag_percentage\n",
    "        total_percentage += tag_percentage\n",
    "\n",
    "    if total_percentage == 0:\n",
    "        return []\n",
    "    scaling_factor = 100 / total_percentage\n",
    "    for tag in tag_percentages:\n",
    "        tag_percentages[tag] *= scaling_factor\n",
    "    results = []\n",
    "    for tag, normalized_percentage in tag_percentages.items():\n",
    "        results.append(tag)\n",
    "        # print(f\"Tag: {tag} ({normalized_percentage}%)\")\n",
    "\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_image(document_name):\n",
    "    # Convert PDF to images with reduced memory usage\n",
    "    temp_image_dir = 'temp_images'\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "    pages = convert_from_path(\n",
    "        f'pdfs/{document_name}.pdf',\n",
    "        dpi=300,\n",
    "        thread_count=2,\n",
    "        output_folder=temp_image_dir\n",
    "    )\n",
    "    return f\"Extract successfully : {len(pages)} documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_txt_from_pdf(document_name, source):\n",
    "    conn = psycopg2.connect(**db_config)\n",
    "    postgres_write = True\n",
    "    \n",
    "    ppm_files = [file for file in os.listdir(\"temp_images\") if file.endswith(\".ppm\")]\n",
    "    \n",
    "    # Apply OCR to each page\n",
    "    if postgres_write:\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "    for i, ppm_file in enumerate(ppm_files, start=0):\n",
    "        ppm_path = os.path.join(\"temp_images\", ppm_file)\n",
    "        extracted_text = pytesseract.image_to_string(ppm_path)\n",
    "        if postgres_write:\n",
    "            cursor.execute(\n",
    "                \"\"\"INSERT INTO pdf_text (document_name,\n",
    "                    page_number,\n",
    "                    text_content,\n",
    "                    present_tags,\n",
    "                    source,\n",
    "                    upload_date,\n",
    "                    user_reading\n",
    "                ) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\", (document_name, i + 1, extracted_text, [\"undefined\"], source, str(datetime.now()), False))\n",
    "            conn.commit()\n",
    "        else:\n",
    "            with open(f'page_{i + 1}.txt', 'w', encoding='utf-8') as text_file:\n",
    "                text_file.write(extracted_text)\n",
    "                \n",
    "        os.remove(ppm_path)\n",
    "\n",
    "    if postgres_write:\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "document_name = [\"ZONE-Udr\"]\n",
    "present_tags = ['règlement', 'zone']\n",
    "source = 'https://www.forcalqueiret.fr/?page_id=222831'\n",
    "city_name = 'Forcalqueiret'\n",
    "\n",
    "os.makedirs(f\"pdfs/used_pdf/{city_name}\", exist_ok=True)\n",
    "for name in document_name:\n",
    "    # convert_pdf_to_image(name)\n",
    "    extract_txt_from_pdf(name, source)\n",
    "    # shutil.move(f\"pdfs/{name}.pdf\", f\"pdfs/used_pdf/{city_name}/{name}.pdf\")\n",
    "    # shutil.move(f\"pdfs/{name}.pdf:Zone.Identifier\", f\"pdfs/used_pdf/{city_name}/{name}.pdf:Zone.Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT id, document_name, page_number, text_content FROM pdf_text ;\" )\n",
    "datas = cursor.fetchall() \n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(datas)\n",
    "df['tags'] = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'tags'] = definition_of_tags(df.at[index, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
